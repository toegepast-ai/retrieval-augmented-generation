# Spatial-Aware RAG with Landing AI ADE

A sophisticated Retrieval-Augmented Generation (RAG) system that processes PDF documents with **spatial intelligence**. Uses Landing AI's Agentic Document Engine (ADE) to extract not just content, but precise location information for enhanced source attribution.

## âœ¨ Key Features

- **ğŸ¯ Spatial Intelligence**: Exact page locations and bounding box coordinates for every piece of content
- **ğŸ¤– Landing AI ADE Integration**: Advanced document parsing with chunk type detection (text, tables, figures)
- **ğŸ“„ Source Attribution**: Responses include precise references to original document locations
- **ğŸ’¾ JSON Export**: Complete spatial data export for advanced analysis
- **ğŸš€ Streamlit Interface**: Interactive web application for document processing and querying
- **ğŸ’° Cost-Effective**: Smart caching system prevents duplicate processing charges

## ğŸ—ï¸ Architecture

```
PDF Document â†’ Landing AI ADE â†’ Spatial Chunks â†’ Vector Database â†’ Location-Aware Responses
     â†“              â†“               â†“              â†“                    â†“
  Raw PDF    Advanced Parsing   Coordinates    Semantic Search    "Found on page 2,
                                & Metadata      & Retrieval        upper-left corner"
```

## ğŸš€ Quick Start

### 1. Setup
```bash
git clone <repository-url>
cd retrieval-augmented-generation
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your API keys
```

### 2. API Keys Required
```bash
# .env file
OPENAI_API_KEY=your-openai-api-key
VISION_AGENT_API_KEY=your-landing-ai-api-key
USE_LANDING_AI=true
```

### 3. Run Application
```bash
streamlit run streamlit_app.py
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/                    # Core RAG pipeline
â”‚   â”œâ”€â”€ rag_pipeline.py     # Main orchestration
â”‚   â”œâ”€â”€ landing_ai_agentic_processor.py  # ADE integration
â”‚   â”œâ”€â”€ embeddings.py       # Text embeddings
â”‚   â””â”€â”€ vector_database.py  # ChromaDB storage
â”œâ”€â”€ config/                 # Configuration
â”œâ”€â”€ data/                   # Data storage
â”œâ”€â”€ streamlit_app.py        # Web interface
â””â”€â”€ requirements.txt        # Dependencies
```

## ğŸ¯ Usage Example

```python
from src.rag_pipeline import MultimodalRAG

config = {
    'openai_api_key': 'your-key',
    'vision_agent_api_key': 'your-landing-ai-key',
    'use_landing_ai': True,
    'chroma_persist_directory': './data/vector_db'
}

rag = MultimodalRAG(config)

# Process document with spatial intelligence
rag.process_document('document.pdf', save_ade_json=True)

# Query with location-aware responses
result = rag.query("What are the key findings?")
print(result['answer'])  # Includes spatial references
```

## ğŸ” What Makes This Special

- **Spatial Awareness**: Unlike traditional RAG systems that lose location context, this system preserves and utilizes spatial information
- **Source Traceability**: Every response can tell you exactly where information came from in the original document
- **Advanced Parsing**: Landing AI ADE provides superior document understanding compared to basic text extraction
- **Cost Optimization**: Smart caching prevents reprocessing the same documents

## ğŸ“Š Supported Content Types

- âœ… **Text**: Paragraphs, headings, lists
- âœ… **Tables**: Structured data with spatial context
- âœ… **Figures**: Charts, graphs, diagrams
- âœ… **Marginalia**: Footnotes, annotations, side notes

## âš™ï¸ Configuration

Key settings in `.env`:
```bash
OPENAI_API_KEY=your-openai-key
VISION_AGENT_API_KEY=your-landing-ai-key
USE_LANDING_AI=true
CHUNK_SIZE=1000
TOP_K=5
```

---

**Built with**: Landing AI ADE â€¢ OpenAI â€¢ ChromaDB â€¢ Streamlit
